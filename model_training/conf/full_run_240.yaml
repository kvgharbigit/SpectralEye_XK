# Complete configuration for 240x240 full training run

defaults:
  - /config
  - override /model: mae_medium_240
  - override /dataset: dataset_240
  - override /augmentation: transform_240

# Optimized hyperparameters for 240x240 full training
hparams:
  batch_size: 2  # Optimal for mae_medium_240 on 11GB GPUs
  nb_epochs: 250
  lr: 0.0001
  valid_interval: 10  # Validation every 10 epochs for long training
  use_gradient_checkpointing: false

# Full dataset training
dataset:
  trial_mode: false

# Enable DDP for faster training
general:
  use_ddp: true
  parallel:
    use_parallel: true
    device_ids: [0, 1]

# Optimized data loading for 240x240 (smaller files load faster)
dataloader:
  num_workers: 2  # Increased from default 2
  pin_memory: true
  prefetch_factor: 4  # Increased from default 2